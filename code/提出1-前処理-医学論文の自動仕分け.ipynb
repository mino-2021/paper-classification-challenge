{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e22c03b",
   "metadata": {},
   "source": [
    "## 医学論文の自動仕分けチャレンジ - 前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c63c990",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gc\n",
    "#from google.colab import drive\n",
    "#drive.mount('/gdrive')\n",
    "\n",
    "#!cp /gdrive/MyDrive/Datasets/signate-471/train.csv .\n",
    "#!cp /gdrive/MyDrive/Datasets/signate-471/test.csv .\n",
    "#!cp /gdrive/MyDrive/Datasets/signate-471/sample_submit.csv ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08c56ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "first-humor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.7/site-packages (3.2.4)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from nltk) (1.15.0)\n",
      "Requirement already satisfied: bs4 in /opt/conda/lib/python3.7/site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.7/site-packages (from bs4) (4.10.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.7/site-packages (from beautifulsoup4->bs4) (2.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "!pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rural-unknown",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b63231f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers as T\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from transformers import (\n",
    "    WEIGHTS_NAME,\n",
    "    AdamW,\n",
    "    AutoConfig,\n",
    "    AutoModel,\n",
    "    AutoTokenizer,\n",
    "    get_cosine_schedule_with_warmup,\n",
    "    get_linear_schedule_with_warmup,\n",
    "    logging,\n",
    "    MODEL_FOR_QUESTION_ANSWERING_MAPPING,\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3a8515e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    batch_size = 12 #5 #16\n",
    "    num_workers = 4 #4\n",
    "    max_length =  256 #72\n",
    "    n_splits =  5 #5\n",
    "    version = 135\n",
    "    drop_rate = 0 #0.1\n",
    "    output_size = 1\n",
    "\n",
    "    model = \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\"\n",
    "    tokenizer = \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\"\n",
    "    epochs = 3 #3\n",
    "    iters_to_accumulate = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85045998",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../input/\"\n",
    "OUTPUT_DIR = \"../output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58bbf96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2c6927f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "594765c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_torch(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed =  471 #471\n",
    "seed_torch(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6107bd10",
   "metadata": {},
   "source": [
    "## データ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b73b316e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(DATA_DIR + \"train.csv\")\n",
    "test = pd.read_csv(DATA_DIR + \"test.csv\")\n",
    "sub = pd.read_csv(DATA_DIR + \"sample_submit.csv\", header=None)\n",
    "sub.columns = [\"id\", \"judgement\"]\n",
    "TARGET = \"judgement\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7eab26",
   "metadata": {},
   "source": [
    "## 前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9e95fc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    " # preprocess\n",
    "train[\"text\"] = train[\"title\"] + \" \" + train[\"abstract\"].fillna(\"\")\n",
    "test[\"text\"] = test[\"title\"] + \" \" + test[\"abstract\"].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "received-authority",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_cv_number(train):\n",
    "    # 交差検証 用の番号を振ります。\n",
    "    Fold = StratifiedKFold(n_splits=CFG.n_splits, shuffle=True, random_state=seed) #5\n",
    "    for n, (train_index, val_index) in enumerate(Fold.split(train, train[TARGET])):\n",
    "        train.loc[val_index, \"fold\"] = int(n)\n",
    "    train[\"fold\"] = train[\"fold\"].astype(np.uint8)\n",
    "\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "magnetic-december",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_data(train):\n",
    "\n",
    "    # 交差検証 用の番号を振ります。\n",
    "    Fold = StratifiedKFold(n_splits=CFG.n_splits, shuffle=True, random_state=seed) #5\n",
    "    for n, (train_index, val_index) in enumerate(Fold.split(train, train[TARGET])):\n",
    "        train.loc[val_index, \"fold\"] = int(n)\n",
    "    train[\"fold\"] = train[\"fold\"].astype(np.uint8)\n",
    "\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "856008b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d675f36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_data(test):\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1ca7c184",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = get_train_data(train)\n",
    "test = get_test_data(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "american-galaxy",
   "metadata": {},
   "source": [
    "## text前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "seeing-equipment",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://zenn.dev/deepblackinc/books/ad568c611643c6/viewer/c37a9f\n",
    "import re\n",
    "import requests\n",
    "import unicodedata\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def clean_text(text):\n",
    "    replaced_text = text.lower()\n",
    "    replaced_text = re.sub(r'[【】]', ' ', replaced_text)       # 【】の除去\n",
    "    replaced_text = re.sub(r'[（）()]', ' ', replaced_text)     # （）の除去\n",
    "    replaced_text = re.sub(r'[［］\\[\\]]', ' ', replaced_text)   # ［］の除去\n",
    "    replaced_text = re.sub(r'[@＠]\\w+', '', replaced_text)  # メンションの除去\n",
    "    replaced_text = re.sub(\n",
    "        r'https?:\\/\\/.*?[\\r\\n ]', '', replaced_text)  # URLの除去\n",
    "    replaced_text = re.sub(r'　', ' ', replaced_text)  # 全角空白の除去\n",
    "    return replaced_text\n",
    "\n",
    "\n",
    "def clean_html_tags(html_text):\n",
    "    soup = BeautifulSoup(html_text, 'html.parser')\n",
    "    cleaned_text = soup.get_text()\n",
    "    cleaned_text = ''.join(cleaned_text.splitlines())\n",
    "    return cleaned_text\n",
    "\n",
    "def clean_html_and_js_tags(html_text):\n",
    "    soup = BeautifulSoup(html_text, 'html.parser')\n",
    "    [x.extract() for x in soup.findAll(['script', 'style'])]\n",
    "    cleaned_text = soup.get_text()\n",
    "    cleaned_text = ''.join(cleaned_text.splitlines())\n",
    "    return cleaned_text\n",
    "\n",
    "def clean_url(html_text):\n",
    "    cleaned_text = re.sub(r'http\\S+', '', html_text)\n",
    "    return cleaned_text\n",
    "\n",
    "def normalize(text):\n",
    "    normalized_text = normalize_unicode(text)\n",
    "    normalized_text = normalize_number(normalized_text)\n",
    "    normalized_text = lower_text(normalized_text)\n",
    "    return normalized_text\n",
    "\n",
    "def lower_text(text):\n",
    "    return text.lower()\n",
    "\n",
    "def normalize_unicode(text, form='NFKC'):\n",
    "    normalized_text = unicodedata.normalize(form, text)\n",
    "    return normalized_text\n",
    "\n",
    "def normalize_number(text):\n",
    "    replaced_text = re.sub(r'\\d+', '0', text)\n",
    "    return replaced_text\n",
    "\n",
    "def lemmatize_term(term, pos=None):\n",
    "    if pos is None:\n",
    "        synsets = wordnet.synsets(term)\n",
    "        if not synsets:\n",
    "            return term\n",
    "        pos = synsets[0].pos()\n",
    "        if pos == wordnet.ADJ_SAT:\n",
    "            pos = wordnet.ADJ\n",
    "    return nltk.WordNetLemmatizer().lemmatize(term, pos=pos)\n",
    "\n",
    "def clean_text2(text):\n",
    "    replaced_text = text.lower()\n",
    "    replaced_text = re.sub(r'objective:', ' ', replaced_text)       # \"\"の除去\n",
    "    replaced_text = re.sub(r'background:', ' ', replaced_text)       # \"\"の除去\n",
    "    replaced_text = re.sub(r'copyright', ' ', replaced_text)       # \"\"の除去\n",
    "    replaced_text = re.sub(r'the', ' ', replaced_text)       # \"\"の除去\n",
    "    return replaced_text\n",
    "\n",
    "\n",
    "def text_cleaning(text):\n",
    "    text = clean_text(text)\n",
    "    text = clean_text2(text)\n",
    "    text = clean_html_tags(text)\n",
    "    text = clean_html_and_js_tags(text)\n",
    "    text = clean_url(text)\n",
    "    text = normalize(text)\n",
    "    text = lower_text(text)\n",
    "    text = normalize_unicode(text)\n",
    "    #text = \"\".join(lemmatize_term(e) for e in text.split())\n",
    "    return text\n",
    "\n",
    "def data_cleaning(data):\n",
    "    return [text_cleaning(text) for text in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "optional-timber",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://zenn.dev/deepblackinc/books/ad568c611643c6/viewer/c37a9f\n",
    "import re\n",
    "import requests\n",
    "import unicodedata\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def text_freq(tmp):\n",
    "    token = nltk.word_tokenize(tmp)\n",
    "    frequency = nltk.FreqDist(w.lower() for w in token)\n",
    "    return ' '.join(map(str, list(frequency.keys())))\n",
    "    #return ' '.join(map(str, list(frequency)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "brilliant-niger",
   "metadata": {},
   "outputs": [],
   "source": [
    "column='text'\n",
    "test[\"text2\"] = test[\"id\"]\n",
    "for i in range(len(test[column])):\n",
    "    test['text2'][i] = text_cleaning(test[column][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "binding-lawyer",
   "metadata": {},
   "outputs": [],
   "source": [
    "column='text'\n",
    "train[\"text2\"] = train[\"id\"]\n",
    "for i in range(len(train[column])):\n",
    "    train['text2'][i] = text_cleaning(train[column][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "broadband-connecticut",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>text</th>\n",
       "      <th>text2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27145</td>\n",
       "      <td>Estimating the potential effects of COVID-19 p...</td>\n",
       "      <td>The objective of the paper is to analyse chang...</td>\n",
       "      <td>Estimating the potential effects of COVID-19 p...</td>\n",
       "      <td>estimating   potential effects of covid-0 pand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27146</td>\n",
       "      <td>Leukoerythroblastic reaction in a patient with...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Leukoerythroblastic reaction in a patient with...</td>\n",
       "      <td>leukoerythroblastic reaction in a patient with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27147</td>\n",
       "      <td>[15O]-water PET and intraoperative brain mappi...</td>\n",
       "      <td>[15O]-water PET was performed on 12 patients w...</td>\n",
       "      <td>[15O]-water PET and intraoperative brain mappi...</td>\n",
       "      <td>0o -water pet and intraoperative brain mappin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27148</td>\n",
       "      <td>Adaptive image segmentation for robust measure...</td>\n",
       "      <td>We present a method that significantly improve...</td>\n",
       "      <td>Adaptive image segmentation for robust measure...</td>\n",
       "      <td>adaptive image segmentation for robust measure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27149</td>\n",
       "      <td>Comparison of Epidemiological Variations in CO...</td>\n",
       "      <td>The objective of this study is to compare the ...</td>\n",
       "      <td>Comparison of Epidemiological Variations in CO...</td>\n",
       "      <td>comparison of epidemiological variations in co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              title  \\\n",
       "0  27145  Estimating the potential effects of COVID-19 p...   \n",
       "1  27146  Leukoerythroblastic reaction in a patient with...   \n",
       "2  27147  [15O]-water PET and intraoperative brain mappi...   \n",
       "3  27148  Adaptive image segmentation for robust measure...   \n",
       "4  27149  Comparison of Epidemiological Variations in CO...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  The objective of the paper is to analyse chang...   \n",
       "1                                                NaN   \n",
       "2  [15O]-water PET was performed on 12 patients w...   \n",
       "3  We present a method that significantly improve...   \n",
       "4  The objective of this study is to compare the ...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Estimating the potential effects of COVID-19 p...   \n",
       "1  Leukoerythroblastic reaction in a patient with...   \n",
       "2  [15O]-water PET and intraoperative brain mappi...   \n",
       "3  Adaptive image segmentation for robust measure...   \n",
       "4  Comparison of Epidemiological Variations in CO...   \n",
       "\n",
       "                                               text2  \n",
       "0  estimating   potential effects of covid-0 pand...  \n",
       "1  leukoerythroblastic reaction in a patient with...  \n",
       "2   0o -water pet and intraoperative brain mappin...  \n",
       "3  adaptive image segmentation for robust measure...  \n",
       "4  comparison of epidemiological variations in co...  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "infinite-private",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>judgement</th>\n",
       "      <th>text</th>\n",
       "      <th>text2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>One-year age changes in MRI brain volumes in o...</td>\n",
       "      <td>Longitudinal studies indicate that declines in...</td>\n",
       "      <td>0</td>\n",
       "      <td>One-year age changes in MRI brain volumes in o...</td>\n",
       "      <td>one-year age changes in mri brain volumes in o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Supportive CSF biomarker evidence to enhance t...</td>\n",
       "      <td>The present study was undertaken to validate t...</td>\n",
       "      <td>0</td>\n",
       "      <td>Supportive CSF biomarker evidence to enhance t...</td>\n",
       "      <td>supportive csf biomarker evidence to enhance  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Occurrence of basal ganglia germ cell tumors w...</td>\n",
       "      <td>Objective: To report a case series in which ba...</td>\n",
       "      <td>0</td>\n",
       "      <td>Occurrence of basal ganglia germ cell tumors w...</td>\n",
       "      <td>occurrence of basal ganglia germ cell tumors w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>New developments in diagnosis and therapy of C...</td>\n",
       "      <td>The etiology and pathogenesis of idiopathic ch...</td>\n",
       "      <td>0</td>\n",
       "      <td>New developments in diagnosis and therapy of C...</td>\n",
       "      <td>new developments in diagnosis and  rapy of cro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Prolonged shedding of SARS-CoV-2 in an elderly...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Prolonged shedding of SARS-CoV-2 in an elderly...</td>\n",
       "      <td>prolonged shedding of sars-cov-0 in an elderly...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title  \\\n",
       "0   0  One-year age changes in MRI brain volumes in o...   \n",
       "1   1  Supportive CSF biomarker evidence to enhance t...   \n",
       "2   2  Occurrence of basal ganglia germ cell tumors w...   \n",
       "3   3  New developments in diagnosis and therapy of C...   \n",
       "4   4  Prolonged shedding of SARS-CoV-2 in an elderly...   \n",
       "\n",
       "                                            abstract  judgement  \\\n",
       "0  Longitudinal studies indicate that declines in...          0   \n",
       "1  The present study was undertaken to validate t...          0   \n",
       "2  Objective: To report a case series in which ba...          0   \n",
       "3  The etiology and pathogenesis of idiopathic ch...          0   \n",
       "4                                                NaN          0   \n",
       "\n",
       "                                                text  \\\n",
       "0  One-year age changes in MRI brain volumes in o...   \n",
       "1  Supportive CSF biomarker evidence to enhance t...   \n",
       "2  Occurrence of basal ganglia germ cell tumors w...   \n",
       "3  New developments in diagnosis and therapy of C...   \n",
       "4  Prolonged shedding of SARS-CoV-2 in an elderly...   \n",
       "\n",
       "                                               text2  \n",
       "0  one-year age changes in mri brain volumes in o...  \n",
       "1  supportive csf biomarker evidence to enhance  ...  \n",
       "2  occurrence of basal ganglia germ cell tumors w...  \n",
       "3  new developments in diagnosis and  rapy of cro...  \n",
       "4  prolonged shedding of sars-cov-0 in an elderly...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "present-shock",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
